# -*- coding: utf-8 -*-
"""LinearRegression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZhtFiS_rowJ0Wfwshzt273BcFkfPqYTH
"""

# Importing essential libraries for data handling, visualization, and modeling
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
import warnings

# Suppress all warnings to keep output clean
warnings.filterwarnings("ignore")

# Load dataset from Kaggle using kagglehub
import kagglehub
import os

path = kagglehub.dataset_download("thedevastator/uncovering-factors-that-affect-used-car-prices")
csv_files = [file for file in os.listdir(path) if file.endswith(".csv")]
df = pd.read_csv(os.path.join(path, csv_files[0]))
df

# View the shape of the dataset
df.shape

# Count missing values in each column
df.isnull().sum()

# Calculate the percentage of missing values in each column of the used car DataFrame
persentage_of_missing = df.isnull().sum().sort_values(ascending=False) * 100 / len(df)
persentage_of_missing

# Dataset structure overview
df.info()

# Convert date columns to datetime and extract useful components
def convert_to_datetime(df, date_cols):
    for col in date_cols:
        df[col] = pd.to_datetime(df[col])
        df[f'{col}_year'] = df[col].dt.year
        df[f'{col}_month'] = df[col].dt.month
        df[f'{col}_day'] = df[col].dt.day
        df[f'{col}_hour'] = df[col].dt.hour

    df.drop(columns=date_cols, inplace=True)
    return df

date_cols = ['dateCrawled', 'dateCreated', 'lastSeen']
convert_to_datetime(df, date_cols)

# Count how many zero values exist per column
zero_counts = (df == 0).sum()
print(zero_counts)

# Drop rows with price equal to zero (invalid)
cols = ['price']
df = df[~(df[cols] == 0).any(axis=1)]

# Re-check zero counts
zero_counts = (df == 0).sum()
print(zero_counts)

# Summary statistics for the target variable
df["price"].describe()

# Clean the dataset by replacing 0s and filling nulls
def clean_dataset_for_regression(df, zero_cols=[], strategy='median'):

    df = df.copy()

    for col in zero_cols:
        df[col + '_was_zero'] = (df[col] == 0).astype(int)
        if strategy == 'median':
            fill_value = df.loc[df[col] != 0, col].median()
        elif strategy == 'mean':
            fill_value = df.loc[df[col] != 0, col].mean()
        else:
            fill_value = df.loc[df[col] != 0, col].mode()[0]
        df[col] = df[col].replace(0, fill_value)

    # Fill missing numeric values
    numeric_cols = df.select_dtypes(include=['number']).columns
    for col in numeric_cols:
        if df[col].isnull().sum() > 0:
            df[col + '_was_null'] = df[col].isnull().astype(int)
            if strategy == 'median':
                df[col] = df[col].fillna(df[col].median())
            elif strategy == 'mean':
                df[col] = df[col].fillna(df[col].mean())
            else:
                df[col] = df[col].fillna(df[col].mode()[0])

    # Fill missing categorical values
    object_cols = df.select_dtypes(include=['object']).columns
    for col in object_cols:
        if df[col].isnull().sum() > 0:
            df[col + '_was_null'] = df[col].isnull().astype(int)
            df[col] = df[col].fillna(df[col].mode()[0])

    return df

# Count how many times the first value of each column appears
def count_first_value_occurrences(df):
    counts = {}
    for col in df.columns:
        first_val = df[col].iloc[0]
        counts[col] = (df[col] == first_val).sum()
        last_df =  pd.DataFrame([counts]).T
        last_df["Total  Observation"] = len(df)
    return last_df

count_first_value_occurrences(df)

# Columns to be cleaned from zeros
zero_columns = ['powerPS', 'dateCrawled_hour', 'lastSeen_hour', 'monthOfRegistration']
df_cleaned = clean_dataset_for_regression(df, zero_cols=zero_columns, strategy='median')
df_cleaned

# Final null check
df_cleaned.isnull().sum()

# Re-check zero values
zero_counts = (df_cleaned == 0).sum()
print(zero_counts)

# Drop unnecessary or irrelevant columns
df = df_cleaned.drop(['index', 'seller', 'offerType', 'nrOfPictures', 'postalCode', 'dateCrawled_year', 'dateCreated_year', 'dateCreated_hour', 'lastSeen_year'], axis=1)
df

# Dataset structure overview
df.info()

# Correlation matrix for numerical features
plt.figure(figsize=(14, 10))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Matrix of Numerical Features")
plt.tight_layout()
plt.show()

# Frequency encoding for categorical features
def frequency_encoding(df, cols):
    copy_df = df.copy()
    for col in cols:
        freq = df[col].value_counts() / len(copy_df)
        copy_df[col + '_freq_enc'] = copy_df[col].map(freq)
    copy_df.drop(columns=cols, inplace=True)
    return copy_df.T

categorical_cols = df.select_dtypes(include=['object']).columns.tolist()

encoding_df = frequency_encoding(df, categorical_cols)
encoding_df

# Remove low variance features (near constant)
def remove_low_variance_columns(df, threshold, verbose=True):
    df_cleaned = df.copy().T
    removed_columns = []

    for col in df_cleaned.select_dtypes(include='number').columns:
        variance = df_cleaned[col].var()
        if variance < threshold:
            removed_columns.append(col)
            df_cleaned.drop(columns=[col], inplace=True)
            if verbose:
                print(f"❌ Column: '{col}' → has low variance ({variance:.6f}), removed.")
        else:
            if verbose:
                print(f"✅ Column: '{col}' → as sufficient variance ({variance:.6f})")

    if verbose and not removed_columns:
        print("No columns removed.")

    return df_cleaned

df = remove_low_variance_columns(encoding_df, threshold=1e-5)

# Basic statistics
df.describe().T

# Additional filtering (removing unrealistic prices/years)
df = df[(df['yearOfRegistration'] >= 1950) & (df['yearOfRegistration'] <= 2024) & (df['price'] >= 1000) ]
df.describe().T # Updated stats

# Outlier removal using IQR method
def remove_outliers(df,column_list):
  result = df.copy()
  for col in column_list:
    Q1 = result[col].quantile(0.25)  # (25th percentile)
    Q3 = result[col].quantile(0.75)  # (75th percentile)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    result = result[(result[col] >= lower_bound) & (result[col] <= upper_bound)]
  return result

df = remove_outliers(df,column_list=["price","powerPS","kilometer"])

# Final stats
df.describe().T

# Log transformation to normalize skewed target variable
def log_transform(df, columns):
  for col in columns:
    df[col + '_log'] = np.log1p(df[col])
    df = df.drop([col], axis=1)

log_transform(df, columns=["price"])

# Prepare features and target variable
y = df['price_log']
X = df.drop(['price_log'], axis=1)

# Fit linear regression model (no train-test split)
reg_model = LinearRegression().fit(X, y)

# Regression coefficients
print("Intercept (bias):", reg_model.intercept_)
print("Coefficients (weights):", reg_model.coef_)

# Evaluate model (on full data)
# MSE RMSE MAE R-Squared
y_pred = reg_model.predict(X)
print("MSE: ",mean_squared_error(y, y_pred))
print("RMSE: ",np.sqrt(mean_squared_error(y, y_pred)))
print("MAE: ",mean_absolute_error(y, y_pred))
print("R²: ",reg_model.score(X, y))

# Mean and standard deviation of target
print("Arithmetic Mean: ", y.mean())
print("Standart Deviation: ", y.std())

# Train-Test split for realistic model evaluation
# Multiple Linear Regression
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=14)
reg_model = LinearRegression().fit(X_train, y_train)

# Coefficients
print("Intercept (bias):", reg_model.intercept_)
print("Coefficients (weights):", reg_model.coef_)

# Train performance
# Train MSE RMSE MAE R-Squared
y_pred = reg_model.predict(X_train)
print("Train MSE: ", mean_squared_error(y_train, y_pred))
print("Train RMSE: ", np.sqrt(mean_squared_error(y_train, y_pred)))
print("Train MAE: ", mean_absolute_error(y_train, y_pred))
print("Train R²: ",reg_model.score(X_train, y_train))

# Test performance
# Test MSE RMSE MAE R-Squared
y_pred = reg_model.predict(X_test)
print("Test MSE: ", mean_squared_error(y_test, y_pred))
print("Test RMSE: ", np.sqrt(mean_squared_error(y_test, y_pred)))
print("Test MAE: ", mean_absolute_error(y_test, y_pred))
print("Test R²: ",reg_model.score(X_test, y_test))

# Visualization: Predicted vs Actual prices (log-transformed)
y_pred = reg_model.predict(X_test)

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.5)
plt.xlabel("Actual Value (y_test)")
plt.ylabel("Predicted Value (y_pred)")
plt.title("Actual vs Predicted Values (Test Set))")
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', color='red')  # reference line
plt.tight_layout()
plt.show()

from sklearn.model_selection import cross_val_score, cross_val_predict

# Cross-validation (10 folds)
cv_value = 10

# MSE scores (note: we take the negative of "neg_mean_squared_error")
cv_scores_mse = -cross_val_score(reg_model, X, y, cv=cv_value, scoring='neg_mean_squared_error')

# RMSE scores (take sqrt of each fold's MSE)
cv_scores_rmse = np.sqrt(cv_scores_mse)

# MAE scores (also negative scoring function, so we negate it)
cv_scores_mae = -cross_val_score(reg_model, X, y, cv=cv_value, scoring='neg_mean_absolute_error')

# R² scores
cv_scores_r2 = cross_val_score(reg_model, X, y, cv=cv_value, scoring='r2')


# 📊 Print all metrics
print(f"🔎 Cross-Validation Results ({cv_value}-Fold):\n")

print(f"MSE scores: {cv_scores_mse}\n")
print(f"Mean MSE: {cv_scores_mse.mean():.4f}\n")

print(f"RMSE scores: {cv_scores_rmse}\n")
print(f"Mean RMSE: {cv_scores_rmse.mean():.4f}\n")

print(f"MAE scores: {cv_scores_mae}\n")
print(f"Mean MAE: {cv_scores_mae.mean():.4f}\n")

print(f"R² scores: {cv_scores_r2}\n")
print(f"Mean R²: {cv_scores_r2.mean():.4f}\n")

# Get predictions from cross-validation (on the full dataset)
y_cv_pred = cross_val_predict(reg_model, X, y, cv=cv_value)

# Scatter plot: Actual vs Predicted (cross-validation)
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y, y=y_cv_pred, alpha=0.5)
plt.xlabel("Actual Values (log price)")
plt.ylabel("Predicted Values (log price)")
plt.title(f"Actual vs Predicted (Cross-Validation, {cv_value}-Fold)")
plt.plot([y.min(), y.max()], [y.min(), y.max()], '--', color='red')  # identity line
plt.tight_layout()
plt.show()

import joblib

# Save the trained model to a file
joblib.dump(reg_model, "used_car_rf_model.pkl")
print("Model saved as 'used_car_rf_model.pkl'")